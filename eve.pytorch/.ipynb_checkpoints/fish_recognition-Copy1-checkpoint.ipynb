{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/nbs/fish/fish_classification/data/sample/sample'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%cd /home/ubuntu/nbs/fish/fish_classification/\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir\n",
    "\n",
    "print DATA_HOME_DIR\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import vgg16, utils\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "from vgg16bn import Vgg16BN\n",
    "from utils import vgg_ft\n",
    "import glob\n",
    "import numpy as np\n",
    "from utils import save_array\n",
    "%matplotlib inline\n",
    "\n",
    "%cd $DATA_HOME_DIR\n",
    "path = DATA_HOME_DIR + '/data/'\n",
    "test_path = path + '/test/' \n",
    "results_path = DATA_HOME_DIR + 'results/'\n",
    "sample_path = path + '/sample/'\n",
    "train_path = path + '/train/'\n",
    "valid_path = path + '/valid/'\n",
    "model_path = path + '/models/'\n",
    "print path, test_path, results_path, train_path, model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/fish/fish_classification/data\n"
     ]
    }
   ],
   "source": [
    "%cd $path\n",
    "%mkdir -p sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/fish/fish_classification/data\n",
      "/home/ubuntu/nbs/fish/fish_classification/data/sample\n"
     ]
    }
   ],
   "source": [
    "%cd $path\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p sample/weights\n",
    "# %mkdir -p test/unknown\n",
    "\n",
    "# %mkdir -p valid/ALB  \n",
    "# %mkdir -p valid/BET  \n",
    "# %mkdir -p valid/DOL  \n",
    "# %mkdir -p valid/LAG  \n",
    "# %mkdir -p valid/NoF  \n",
    "# %mkdir -p valid/OTHER  \n",
    "# %mkdir -p valid/SHARK  \n",
    "# %mkdir -p valid/YFT\n",
    "\n",
    "%cd $sample_path \n",
    "%mkdir -p train/ALB  \n",
    "%mkdir -p train/BET  \n",
    "%mkdir -p train/DOL  \n",
    "%mkdir -p train/LAG  \n",
    "%mkdir -p train/NoF  \n",
    "%mkdir -p train/OTHER  \n",
    "%mkdir -p train/SHARK  \n",
    "%mkdir -p train/YFT\n",
    "%mkdir -p valid/ALB  \n",
    "%mkdir -p valid/BET  \n",
    "%mkdir -p valid/DOL  \n",
    "%mkdir -p valid/LAG  \n",
    "%mkdir -p valid/NoF  \n",
    "%mkdir -p valid/OTHER  \n",
    "%mkdir -p valid/SHARK  \n",
    "%mkdir -p valid/YFT\n",
    "%mkdir -p test/ALB  \n",
    "%mkdir -p test/BET  \n",
    "%mkdir -p test/DOL  \n",
    "%mkdir -p test/LAG  \n",
    "%mkdir -p test/NoF  \n",
    "%mkdir -p test/OTHER  \n",
    "%mkdir -p test/SHARK  \n",
    "%mkdir -p test/YFT\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shutil import copyfile\n",
    "for i in ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']:\n",
    "    train_path_one_fish = train_path + \"{}\".format(i)\n",
    "    valid_path_one_fish = valid_path + \"/{}/\".format(i) \n",
    "    %cd $train_path_one_fish\n",
    "    g = glob.glob('*.jpg')\n",
    "    print len(g)/10\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(len(g)/10): \n",
    "        os.rename(shuf[i], valid_path_one_fish + shuf[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shutil import copyfile\n",
    "for i in ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']:\n",
    "    train_path_one_fish = train_path + \"{}\".format(i) \n",
    "    sample_path_one_fish = sample_path + \"train/{}/\".format(i) \n",
    "    %cd $train_path_one_fish\n",
    "    g = glob.glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(len(g)/10 * 8): \n",
    "        os.rename(shuf[i], sample_path_one_fish + shuf[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shutil import copyfile\n",
    "%cd $path\n",
    "for i in ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']:\n",
    "    #valid_path_one_fish = valid_path + \"/{}/\".format(i) \n",
    "    train_path_one_fish = train_path + \"{}\".format(i)\n",
    "    sample_valid_path_one_fish = sample_path + \"valid/{}/\".format(i)\n",
    "    print sample_valid_path_one_fish\n",
    "    #%cd $valid_path_one_fish\n",
    "    %cd $train_path_one_fish\n",
    "    g = glob.glob('*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(len(g)/10): \n",
    "        os.rename(shuf[i], sample_valid_path_one_fish + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        keras.layers.pooling.MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        keras.layers.Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.),\n",
    "        Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.),\n",
    "        Dense(8, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    for l1,l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def proc_wgts(layer): \n",
    "    return [o/2 for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# path = \"data/sample/\"\n",
    "# path = \"data/fish/\"\n",
    "batch_size=64\n",
    "\n",
    "(val_classes, trn_classes, test_classes, val_labels, trn_labels, test_labels,\n",
    "    val_filenames, filenames, test_filenames) = get_classes(sample_path)\n",
    "\n",
    "batches = get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = get_batches(valid_path, batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/fish/fish_classification/data//sample/\n"
     ]
    }
   ],
   "source": [
    "print sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg_ft_bn(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16\n",
    "model = vgg_ft(8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-2\n",
    "model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=5, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2984 images belonging to 8 classes.\n",
      "Found 394 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# trn = get_data(path+'sample/train')\n",
    "# val = get_data(path+'sample/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# test = get_data(path+'sample/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??image.ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_array(path+'results/trn.dat', trn)\n",
    "# save_array(path+'results/val.dat', val)\n",
    "# save_array(path+'results/test.dat', test)\n",
    "trn = load_array(path+'results/trn.dat')\n",
    "val = load_array(path+'results/val.dat')\n",
    "test = load_array(path+'results/test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-2),\n",
    "       loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=3, \n",
    "             validation_data=(conv_val_feat, val_labels),callbacks=[history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras import optimizers\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/ft2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers,fc_layers = split_at(model, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 512, 14, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv_model = Sequential(conv_layers)\n",
    "# conv_feat = conv_model.predict(trn)\n",
    "# conv_val_feat = conv_model.predict(val)\n",
    "# conv_test_feat = conv_model.predict(test)\n",
    "# save_array(path+'results/conv_val_feat.dat', conv_val_feat)\n",
    "# save_array(path+'results/conv_feat.dat', conv_feat)\n",
    "# save_array(path+'results/conv_test_feat.dat', conv_test_feat)\n",
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_test_feat = load_array(path+'results/conv_test_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "#         BatchNormalization(axis=1),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(p/2),\n",
    "#         BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(p/2),\n",
    "        BatchNormalization(),\n",
    "        Dense(8, activation='softmax')\n",
    "    ]\n",
    "p=1\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=5, \n",
    "#              validation_data=(conv_val_feat, val_labels),callbacks=[history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=5, \n",
    "             validation_data=(conv_val_feat, val_labels),callbacks=[history])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 282.00 556.00\" width=\"282pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-552 278,-552 278,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140695358911184 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140695358911184</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 274,-547.5 274,-511.5 0,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-525.8\">maxpooling2d_input_3 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140695358906192 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140695358906192</title>\n",
       "<polygon fill=\"none\" points=\"6,-438.5 6,-474.5 268,-474.5 268,-438.5 6,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-452.8\">maxpooling2d_13 (MaxPooling2D)</text>\n",
       "</g>\n",
       "<!-- 140695358911184&#45;&gt;140695358906192 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140695358911184-&gt;140695358906192</title>\n",
       "<path d=\"M137,-511.313C137,-503.289 137,-493.547 137,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-484.529 137,-474.529 133.5,-484.529 140.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358906128 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140695358906128</title>\n",
       "<polygon fill=\"none\" points=\"64,-365.5 64,-401.5 210,-401.5 210,-365.5 64,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-379.8\">flatten_5 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 140695358906192&#45;&gt;140695358906128 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140695358906192-&gt;140695358906128</title>\n",
       "<path d=\"M137,-438.313C137,-430.289 137,-420.547 137,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-411.529 137,-401.529 133.5,-411.529 140.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358906320 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140695358906320</title>\n",
       "<polygon fill=\"none\" points=\"65.5,-292.5 65.5,-328.5 208.5,-328.5 208.5,-292.5 65.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-306.8\">dense_15 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140695358906128&#45;&gt;140695358906320 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140695358906128-&gt;140695358906320</title>\n",
       "<path d=\"M137,-365.313C137,-357.289 137,-347.547 137,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-338.529 137,-328.529 133.5,-338.529 140.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358910608 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140695358910608</title>\n",
       "<polygon fill=\"none\" points=\"55.5,-219.5 55.5,-255.5 218.5,-255.5 218.5,-219.5 55.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-233.8\">dropout_9 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 140695358906320&#45;&gt;140695358910608 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140695358906320-&gt;140695358910608</title>\n",
       "<path d=\"M137,-292.313C137,-284.289 137,-274.547 137,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-265.529 137,-255.529 133.5,-265.529 140.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358910672 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140695358910672</title>\n",
       "<polygon fill=\"none\" points=\"65.5,-146.5 65.5,-182.5 208.5,-182.5 208.5,-146.5 65.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-160.8\">dense_16 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140695358910608&#45;&gt;140695358910672 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140695358910608-&gt;140695358910672</title>\n",
       "<path d=\"M137,-219.313C137,-211.289 137,-201.547 137,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-192.529 137,-182.529 133.5,-192.529 140.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358910800 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140695358910800</title>\n",
       "<polygon fill=\"none\" points=\"51,-73.5 51,-109.5 223,-109.5 223,-73.5 51,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-87.8\">dropout_10 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 140695358910672&#45;&gt;140695358910800 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140695358910672-&gt;140695358910800</title>\n",
       "<path d=\"M137,-146.313C137,-138.289 137,-128.547 137,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-119.529 137,-109.529 133.5,-119.529 140.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695358910864 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140695358910864</title>\n",
       "<polygon fill=\"none\" points=\"65.5,-0.5 65.5,-36.5 208.5,-36.5 208.5,-0.5 65.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137\" y=\"-14.8\">dense_17 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140695358910800&#45;&gt;140695358910864 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140695358910800-&gt;140695358910864</title>\n",
       "<path d=\"M137,-73.3129C137,-65.2895 137,-55.5475 137,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.5,-46.5288 137,-36.5288 133.5,-46.5289 140.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "SVG(model_to_dot(bn_model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 606.00 387.00\" width=\"606pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-383 602,-383 602,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140695352835280 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140695352835280</title>\n",
       "<polygon fill=\"none\" points=\"95.5,-332.5 95.5,-378.5 493.5,-378.5 493.5,-332.5 95.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-351.8\">input_15 (InputLayer)</text>\n",
       "<polyline fill=\"none\" points=\"270.5,-332.5 270.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"270.5,-355.5 338.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"338.5,-332.5 338.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416\" y=\"-363.3\">(None, 512, 14, 14)</text>\n",
       "<polyline fill=\"none\" points=\"338.5,-355.5 493.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416\" y=\"-340.3\">(None, 512, 14, 14)</text>\n",
       "</g>\n",
       "<!-- 140695350458768 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140695350458768</title>\n",
       "<polygon fill=\"none\" points=\"52,-249.5 52,-295.5 537,-295.5 537,-249.5 52,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-268.8\">maxpooling2d_54 (MaxPooling2D)</text>\n",
       "<polyline fill=\"none\" points=\"314,-249.5 314,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"314,-272.5 382,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"382,-249.5 382,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459.5\" y=\"-280.3\">(None, 512, 14, 14)</text>\n",
       "<polyline fill=\"none\" points=\"382,-272.5 537,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459.5\" y=\"-257.3\">(None, 512, 14, 7)</text>\n",
       "</g>\n",
       "<!-- 140695352835280&#45;&gt;140695350458768 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140695352835280-&gt;140695350458768</title>\n",
       "<path d=\"M294.5,-332.366C294.5,-324.152 294.5,-314.658 294.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"298,-305.607 294.5,-295.607 291,-305.607 298,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695350775760 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140695350775760</title>\n",
       "<polygon fill=\"none\" points=\"17.5,-166.5 17.5,-212.5 571.5,-212.5 571.5,-166.5 17.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-185.8\">batchnormalization_52 (BatchNormalization)</text>\n",
       "<polyline fill=\"none\" points=\"357.5,-166.5 357.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"357.5,-189.5 425.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"425.5,-166.5 425.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498.5\" y=\"-197.3\">(None, 512, 14, 7)</text>\n",
       "<polyline fill=\"none\" points=\"425.5,-189.5 571.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498.5\" y=\"-174.3\">(None, 512, 14, 7)</text>\n",
       "</g>\n",
       "<!-- 140695350458768&#45;&gt;140695350775760 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140695350458768-&gt;140695350775760</title>\n",
       "<path d=\"M294.5,-249.366C294.5,-241.152 294.5,-231.658 294.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"298,-222.607 294.5,-212.607 291,-222.607 298,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695350459280 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140695350459280</title>\n",
       "<polygon fill=\"none\" points=\"114.5,-83.5 114.5,-129.5 474.5,-129.5 474.5,-83.5 114.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-102.8\">flatten_8 (Flatten)</text>\n",
       "<polyline fill=\"none\" points=\"260.5,-83.5 260.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"260.5,-106.5 328.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"328.5,-83.5 328.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-114.3\">(None, 512, 14, 7)</text>\n",
       "<polyline fill=\"none\" points=\"328.5,-106.5 474.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401.5\" y=\"-91.3\">(None, 50176)</text>\n",
       "</g>\n",
       "<!-- 140695350775760&#45;&gt;140695350459280 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140695350775760-&gt;140695350459280</title>\n",
       "<path d=\"M294.5,-166.366C294.5,-158.152 294.5,-148.658 294.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"298,-139.607 294.5,-129.607 291,-139.607 298,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695350224656 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140695350224656</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-46.5 281,-46.5 281,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"47\" y=\"-19.8\">bb (Dense)</text>\n",
       "<polyline fill=\"none\" points=\"94,-0.5 94,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"94,-23.5 162,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"162,-0.5 162,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-31.3\">(None, 50176)</text>\n",
       "<polyline fill=\"none\" points=\"162,-23.5 281,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-8.3\">(None, 4)</text>\n",
       "</g>\n",
       "<!-- 140695350459280&#45;&gt;140695350224656 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140695350459280-&gt;140695350224656</title>\n",
       "<path d=\"M252.419,-83.3664C233.575,-73.4551 211.192,-61.682 191.413,-51.2787\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"193.01,-48.1643 182.53,-46.6068 189.751,-54.3596 193.01,-48.1643\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140695350223760 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140695350223760</title>\n",
       "<polygon fill=\"none\" points=\"299,-0.5 299,-46.5 598,-46.5 598,-0.5 299,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"355\" y=\"-19.8\">class (Dense)</text>\n",
       "<polyline fill=\"none\" points=\"411,-0.5 411,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"411,-23.5 479,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"479,-0.5 479,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"538.5\" y=\"-31.3\">(None, 50176)</text>\n",
       "<polyline fill=\"none\" points=\"479,-23.5 598,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"538.5\" y=\"-8.3\">(None, 8)</text>\n",
       "</g>\n",
       "<!-- 140695350459280&#45;&gt;140695350223760 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140695350459280-&gt;140695350223760</title>\n",
       "<path d=\"M336.581,-83.3664C355.425,-73.4551 377.808,-61.682 397.587,-51.2787\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"399.249,-54.3596 406.47,-46.6068 395.99,-48.1643 399.249,-54.3596\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# Show the model in ipython notebook\n",
    "figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "display(figure)\n",
    "\n",
    "# Save the model as png file\n",
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model_final.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proc_wgts(layer): return [o/2 for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(8, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    for l1,l2 in zip(model.layers, fc_layers): l1.set_weights(proc_wgts(l2))\n",
    "    model.compile(Adam(lr=0.01),loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=3, \n",
    "#              validation_data=(conv_val_feat, val_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_acc=[]\n",
    "val_class_acc=[]\n",
    "class_loss=[]\n",
    "val_class_loss=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_list = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_acc_percent = []\n",
    "for i in class_acc:\n",
    "    i = i * 100\n",
    "    class_acc_percent.append(i)\n",
    "    \n",
    "val_class_acc_percent = []\n",
    "for i in val_class_acc:\n",
    "    i = i * 100\n",
    "    val_class_acc_percent.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "bn_model.optimizer.lr = 0.01\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['acc']\n",
    "val_class_acc += history_list['val_acc']\n",
    "class_loss += history_list['loss']\n",
    "val_class_loss += history_list['val_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bn_model.evaluate(conv_test_feat, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??plt.plot\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trn = get_data(path+'sample/train', (360,640))\n",
    "val = get_data(path+'sample/valid', (360,640))\n",
    "test = get_data(path+'sample/test', (360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/trn_640.dat', trn)\n",
    "save_array(path+'results/val_640.dat', val)\n",
    "save_array(path+'results/test_640.dat', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn = load_array(path+'results/trn_640.dat')\n",
    "val = load_array(path+'results/val_640.dat')\n",
    "test = load_array(path+'results/test_640.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg640 = Vgg16BN((360, 640)).model\n",
    "vgg640.pop()\n",
    "vgg640.input_shape, vgg640.output_shape\n",
    "vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# conv_val_feat = vgg640.predict(val, batch_size=32, verbose=1)\n",
    "# conv_trn_feat = vgg640.predict(trn, batch_size=32, verbose=1)\n",
    "# save_array(path+'results/conv_val_640.dat', conv_val_feat)\n",
    "# save_array(path+'results/conv_trn_640.dat', conv_trn_feat)\n",
    "# conv_test_feat = vgg640.predict(test, batch_size=32, verbose=1)\n",
    "# save_array(path+'results/conv_test_640.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_val_feat = load_array(path+'results/conv_val_640.dat')\n",
    "conv_trn_feat = load_array(path+'results/conv_trn_640.dat')\n",
    "conv_test_feat = load_array(path+'results/conv_test_640.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, nb_filter, nb_row, nb_col, subsample=(1, 1)):\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample, activation='relu', border_mode='same')(x)\n",
    "    return BatchNormalization(axis=1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def incep_block(x):\n",
    "    branch1x1 = conv2d_bn(x, 32, 1, 1, subsample=(2, 2))\n",
    "    branch5x5 = conv2d_bn(x, 24, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 32, 5, 5, subsample=(2, 2))\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 32, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 48, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 48, 3, 3, subsample=(2, 2))\n",
    "\n",
    "    branch_pool = AveragePooling2D(\n",
    "        (3, 3), strides=(2, 2), border_mode='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 16, 1, 1)\n",
    "    return merge([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "              mode='concat', concat_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(vgg640.layers[-1].output_shape[1:]) \n",
    "# x = BatchNormalization(axis=1)(inp)\n",
    "# x = incep_block(x)\n",
    "# x = incep_block(x)\n",
    "# x = incep_block(x)\n",
    "# x = Dropout(0.75)(x)\n",
    "# x = Convolution2D(8,3,3, border_mode='same')(x)\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# outp = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model = Model([inp], outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.optimizer.lr = 0.00001\n",
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=15, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['acc']\n",
    "val_class_acc += history_list['val_acc']\n",
    "class_loss += history_list['loss']\n",
    "val_class_loss += history_list['val_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.evaluate(conv_val_feat, val_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(class_acc_percent)\n",
    "plt.plot(val_class_acc_percent)\n",
    "plt.title('Google Net accuracy')\n",
    "plt.ylabel('accuracy(%)')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(0, 104, 4))\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(class_loss)\n",
    "plt.plot(val_class_loss)\n",
    "plt.title('Google Net loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(0, 8, 0.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(class_acc_percent)\n",
    "plt.plot(val_class_acc_percent)\n",
    "plt.title('improved model accuracy')\n",
    "plt.ylabel('accuracy(%)')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(40, 103, 3))\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(class_loss)\n",
    "plt.plot(val_class_loss)\n",
    "plt.title('improved model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.yticks(np.arange(0, 8, 0.3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/conv_512_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.evaluate(conv_val_feat, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers,_ = split_at(vgg640, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(8,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())\n",
    "lrg_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, val_labels), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.optimizer.lr=1e-2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['acc']\n",
    "val_class_acc += history_list['val_acc']\n",
    "class_loss += history_list['loss']\n",
    "val_class_loss += history_list['val_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrg_model.optimizer.lr=1e-3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lrg_model.fit(conv_trn_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['acc']\n",
    "val_class_acc += history_list['val_acc']\n",
    "class_loss += history_list['loss']\n",
    "val_class_loss += history_list['val_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "anno_classes = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft']\n",
    "\n",
    "bb_json = {}\n",
    "for c in anno_classes:\n",
    "    j = json.load(open('{}/{}_labels.json'.format(path, c), 'r'))\n",
    "    for l in j:\n",
    "        if 'annotations' in l.keys() and len(l['annotations'])>0:\n",
    "            bb_json[l['filename'].split('/')[-1]] = sorted(\n",
    "                l['annotations'], key=lambda x: x['height']*x['width'])[-1]\n",
    "            \n",
    "file2idx = {o:i for i,o in enumerate(raw_filenames)}\n",
    "val_file2idx = {o:i for i,o in enumerate(raw_val_filenames)}\n",
    "test_file2idx = {o:i for i,o in enumerate(raw_test_filenames)}\n",
    "\n",
    "empty_bbox = {'height': 0., 'width': 0., 'x': 0., 'y': 0.}\n",
    "\n",
    "for f in raw_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "for f in raw_val_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "for f in raw_test_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "        \n",
    "sizes = [PIL.Image.open(path+'sample/train/'+f).size for f in filenames]\n",
    "raw_val_sizes = [PIL.Image.open(path+'sample/valid/'+f).size for f in val_filenames]\n",
    "raw_test_sizes = [PIL.Image.open(path+'sample/test/'+f).size for f in test_filenames]\n",
    "\n",
    "bb_params = ['height', 'width', 'x', 'y']\n",
    "def convert_bb(bb, size):\n",
    "    bb = [bb[p] for p in bb_params]\n",
    "    conv_x = (224. / size[0])\n",
    "    conv_y = (224. / size[1])\n",
    "    bb[0] = bb[0]*conv_y\n",
    "    bb[1] = bb[1]*conv_x\n",
    "    bb[2] = max(bb[2]*conv_x, 0)\n",
    "    bb[3] = max(bb[3]*conv_y, 0)\n",
    "    return bb\n",
    "            \n",
    "    \n",
    "trn_bbox = np.stack([convert_bb(bb_json[f], s) for f,s in zip(raw_filenames, sizes)], \n",
    "                   ).astype(np.float32)\n",
    "val_bbox = np.stack([convert_bb(bb_json[f], s) \n",
    "                   for f,s in zip(raw_val_filenames, raw_val_sizes)]).astype(np.float32)\n",
    "test_bbox = np.stack([convert_bb(bb_json[f], s) \n",
    "                   for f,s in zip(raw_test_filenames, raw_test_sizes)]).astype(np.float32)\n",
    "\n",
    "def create_rect(bb, color='red'):\n",
    "    return plt.Rectangle((bb[2], bb[3]), bb[1], bb[0], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_bb(i):\n",
    "    bb = val_bbox[i]\n",
    "    plot(val[i])\n",
    "    plt.gca().add_patch(create_rect(bb))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bb_json['img_04908.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file2idx = {o:i for i,o in enumerate(raw_filenames)}\n",
    "val_file2idx = {o:i for i,o in enumerate(raw_val_filenames)}\n",
    "test_file2idx = {o:i for i,o in enumerate(raw_test_filenames)}\n",
    "\n",
    "empty_bbox = {'height': 0., 'width': 0., 'x': 0., 'y': 0.}\n",
    "\n",
    "for f in raw_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "for f in raw_val_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox\n",
    "for f in raw_test_filenames:\n",
    "    if not f in bb_json.keys(): bb_json[f] = empty_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = [PIL.Image.open(path+'sample/train/'+f).size for f in filenames]\n",
    "raw_val_sizes = [PIL.Image.open(path+'sample/valid/'+f).size for f in val_filenames]\n",
    "raw_test_sizes = [PIL.Image.open(path+'sample/test/'+f).size for f in test_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb_params = ['height', 'width', 'x', 'y']\n",
    "def convert_bb(bb, size):\n",
    "    bb = [bb[p] for p in bb_params]\n",
    "    conv_x = (224. / size[0])\n",
    "    conv_y = (224. / size[1])\n",
    "    bb[0] = bb[0]*conv_y\n",
    "    bb[1] = bb[1]*conv_x\n",
    "    bb[2] = max(bb[2]*conv_x, 0)\n",
    "    bb[3] = max(bb[3]*conv_y, 0)\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_bbox = np.stack([convert_bb(bb_json[f], s) for f,s in zip(raw_filenames, sizes)], \n",
    "                   ).astype(np.float32)\n",
    "val_bbox = np.stack([convert_bb(bb_json[f], s) \n",
    "                   for f,s in zip(raw_val_filenames, raw_val_sizes)]).astype(np.float32)\n",
    "test_bbox = np.stack([convert_bb(bb_json[f], s) \n",
    "                   for f,s in zip(raw_test_filenames, raw_test_sizes)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print trn_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rect(bb, color='red'):\n",
    "    return plt.Rectangle((bb[2], bb[3]), bb[1], bb[0], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_bb(i):\n",
    "    bb = val_bbox[i]\n",
    "    plot(val[i])\n",
    "    plt.gca().add_patch(create_rect(bb))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "show_bb(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(8,3,3, border_mode='same'),\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "lrg_model = Sequential(get_lrg_layers())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inp = Input(conv_layers[-1].output_shape[1:])\n",
    "# x = MaxPooling2D()(inp)\n",
    "x = BatchNormalization(axis=1, input_shape=(512,14,14))(inp)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(p)(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(p/2)(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x_bb = Dense(4, name='bb')(x)\n",
    "x_class = Dense(8, activation='softmax', name='class')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n",
      "th\n"
     ]
    }
   ],
   "source": [
    "x = BatchNormalization(axis=1, input_shape=(512,14,14))(inp)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Convolution2D(128,3,3, activation='relu', border_mode='same')(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x_b = Convolution2D(4,3,3, border_mode='same')(x)\n",
    "x_bb = GlobalAveragePooling2D(name='bb')(x_b)\n",
    "x_c = Convolution2D(8,3,3, border_mode='same')(x)\n",
    "x_c = GlobalAveragePooling2D()(x_c)\n",
    "x_class = Activation('softmax', name = 'class')(x_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp], [x_bb, x_class])\n",
    "model.compile(Adam(lr=0.01), loss=['mse', 'categorical_crossentropy'], metrics=['accuracy'],\n",
    "             loss_weights=[.001, 1.])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# Show the model in ipython notebook\n",
    "figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "display(figure)\n",
    "\n",
    "# Save the model as png file\n",
    "from keras.utils.visualize_util import plot\n",
    "# plot(model, to_file='model_final.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_acc=[]\n",
    "val_class_acc=[]\n",
    "class_loss=[]\n",
    "val_class_loss=[]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.optimizer.lr = 1e-2\n",
    "\n",
    "model.fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "\n",
    "model.fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "\n",
    "model.fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit(conv_trn_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=5, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "class_acc = class_acc[0:9]\n",
    "val_class_acc = val_class_acc[0:9]\n",
    "class_loss = class_loss[0:9]\n",
    "val_class_loss = val_class_loss[0:9]\n",
    "print len(class_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "model.optimizer.lr = 0.01\n",
    "\n",
    "model.fit(conv_feat, [trn_bbox, trn_labels], batch_size=batch_size, nb_epoch=5, \n",
    "             validation_data=(conv_val_feat, [val_bbox, val_labels]), callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "history_list = history.history\n",
    "class_acc += history_list['class_acc']\n",
    "val_class_acc += history_list['val_class_acc']\n",
    "class_loss += history_list['class_loss']\n",
    "val_class_loss += history_list['val_class_loss']\n",
    "print len(class_acc)\n",
    "# print class_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.evaluate(conv_test_feat, [test_bbox, test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'models/bn_anno02.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = image.ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=90, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, width_zoom_range=0.2, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, channel_shift_range=10., horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.05,width_zoom_range=0.05, height_shift_range=0.05, shear_range=0.05, zoom_range=0.05, channel_shift_range=10, horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "batch_size = 64\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches(valid_path, shuffle=False, batch_size=batch_size)\n",
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "opt = RMSprop(lr=0.00001, rho=0.7)\n",
    "model = vgg_ft(8)\n",
    "layers = model.layers\n",
    "last_conv_idx = [index for index,layer in enumerate(layers) if type(layer) is keras.layers.convolutional.Convolution2D][-1]\n",
    "# fc_layers = layers[last_conv_idx+1:]\n",
    "conv_layers = layers[:last_conv_idx+1]\n",
    "conv_model = Sequential(conv_layers)\n",
    "# fc_model = get_fc_model()\n",
    "for layer in conv_model.layers: layer.trainable = False\n",
    "# Look how easy it is to connect two models together!\n",
    "# conv_model.add(fc_model)\n",
    "conv_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.save_weights(model_path + 'aug4.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_model.load_weights(model_path + 'final1.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv_layers[-1].output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.6\n",
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(8, activation='softmax')\n",
    "        ]\n",
    "bn_model = Sequential(get_bn_layers(0.6))\n",
    "bn_layers = get_bn_layers(0.6)\n",
    "bn_layers.pop()\n",
    "bn_layers.append(Dense(8,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = Sequential(conv_layers)\n",
    "for layer in final_model.layers: layer.trainable = False\n",
    "for layer in bn_layers: final_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer=Adam(), \n",
    "                    loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final_model.optimizer.lr.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.save_weights(model_path + 'final1.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "bn_model.load_weights(model_path + 'final1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "preds = bn_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = preds.clip(min=0.05, max=0.95)\n",
    "print preds[:5]\n",
    "filenames = test_batches.filenames\n",
    "ids = np.array([(f[f.find('/')+1:]) for f in filenames])\n",
    "ids.resize((1000, 1))\n",
    "subm = np.hstack((ids,preds))\n",
    "print subm[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission_aug03.csv'\n",
    "print subm[:5]\n",
    "np.savetxt(submission_file_name, subm, fmt='%s,%s,%s,%s,%s,%s,%s,%s,%s', header='image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT', comments='')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink('/home/ubuntu/nbs/fish/fish_classification/'+submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 373 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# gen = image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, width_zoom_range=0.2, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, channel_shift_range=10., horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.05,width_zoom_range=0.05, height_shift_range=0.05, shear_range=0.05, zoom_range=0.05, channel_shift_range=10, horizontal_flip=True)\n",
    "\n",
    "# gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "# gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, height_shift_range=0.08, zoom_range=0.08, shear_range=0.3)\n",
    "\n",
    "batch_size = 64\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches(valid_path, shuffle=False, batch_size=batch_size)\n",
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "# from keras import backend as K\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "def get_bn_layers(conv_layers, p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        BatchNormalization(),\n",
    "        Dense(8, activation='softmax')\n",
    "            ]\n",
    "\n",
    "def get_model():\n",
    "    model = vgg_ft(8)\n",
    "    layers = model.layers\n",
    "    last_conv_idx = [index for index,layer in enumerate(layers) if type(layer) is keras.layers.convolutional.Convolution2D][-1]\n",
    "    conv_layers = layers[:last_conv_idx+1]\n",
    "    final_model = Sequential(conv_layers)\n",
    "    drop_out_rate=0.5\n",
    "    bn_model = Sequential(get_bn_layers(conv_layers, drop_out_rate))\n",
    "    bn_layers = get_bn_layers(conv_layers, drop_out_rate)\n",
    "    bn_layers.pop()\n",
    "    bn_layers.append(Dense(8,activation='softmax'))\n",
    "    for layer in final_model.layers: \n",
    "        layer.trainable = False\n",
    "    for layer in bn_layers: \n",
    "        final_model.add(layer)\n",
    "    for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "        l2.set_weights(l1.get_weights())\n",
    "    final_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model()\n",
    "#     model.optimizer.lr=0.001\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=1, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "    \n",
    "#     model.optimizer.lr=0.1\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.1 learning rate ------------done----------')\n",
    "#     model.optimizer.lr=0.01\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.01 learning rate ------------done----------')\n",
    "#     model.optimizer.lr=0.001\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.001 learning rate ------------done----------')\n",
    "#     model.optimizer.lr=0.0001\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.0001 learning rate ------------done----------')\n",
    "#     model.optimizer.lr=0.00001\n",
    "#     model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "#     print ('0.00001 learning rate ------------done----------')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models.save_weights(path + 'sample_vertical_and_horizontal_flip03.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "models = fit_model() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loop = 1\n",
    "for i in range(loop):\n",
    "    gen = image.ImageDataGenerator()\n",
    "    print (i, 'no')\n",
    "    batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "    models = fit_model()\n",
    "loop = 1\n",
    "for i in range(loop):\n",
    "    gen = image.ImageDataGenerator(shear_range=0.05)\n",
    "    print (i, 'shear_range=0.05')\n",
    "    batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "    models = fit_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3777 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(channel_shift_range=10)\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "model_01 = fit_model()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data= get_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_01.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.save_weights(path + 'vgg_shear0.05_dropout0.5_model02_subset01.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = image.ImageDataGenerator(shear_range=0.05)\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "model_01 = fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.save_weights(path + 'vgg_shear0.05_dropout0.5_model03_subset01.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "gen_train = image.ImageDataGenerator()\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "model_01 = fit_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_data = get_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model_01.predict(test_data, batch_size = batch_size * 2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test_batches = gen.flow(test_data, preds, batch_size = 16)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "val_batches = get_batches(valid_path, batch_size = 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_batches = get_batches(train_path, gen_train, batch_size = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3404"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches.N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??MixIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mi = MixIterator([train_batches, test_batches, val_batches])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.save_weights(path + 'vgg_shear0.05_dropout0.5_model02_subset02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'vgg_shear0.05_dropout0.5_model01_subset01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'vgg_mnist_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'vgg_mnist_0_sub10.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "val_batches.nb_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 373 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = get_data(valid_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(mi, mi.N, nb_epoch=8, validation_data=(val_data, val_labels))\n",
    "\n",
    "# model_01.optimizer.lr=0.000005\n",
    "# model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=5, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "# model_01.optimizer.lr=0.000005\n",
    "# model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'trainset_01shear0.05_02no_aug_dropout0.5_model_mnist_0_sub02.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "# model_01.optimizer.lr=0.000005\n",
    "# model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "#                         validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "model_01.save_weights(path + 'trainset_01shear0.05_02no_aug_dropout0.5_model_mnist_0_sub04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'trainset_01shear0.05_02no_aug_dropout0.5_model_mnist_0_sub03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.load_weights(path + 'vgg_mnist_1.h5')\n",
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.optimizer.lr=0.000005\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.save_weights(path + 'vgg_mnist_1_sub02.h5')\n",
    "\n",
    "\n",
    "\n",
    "model_01.load_weights(path + 'vgg_mnist_1.h5')\n",
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.optimizer.lr=0.000005\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.save_weights(path + 'vgg_mnist_1_sub02.h5')\n",
    "\n",
    "model_01.load_weights(path + 'vgg_mnist_2.h5')\n",
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.optimizer.lr=0.000005\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.save_weights(path + 'vgg_mnist_2_sub02.h5')\n",
    "\n",
    "model_01.load_weights(path + 'vgg_mnist_3.h5')\n",
    "model_01.optimizer.lr=0.00001\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.optimizer.lr=0.000005\n",
    "model_01.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=10, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "model_01.save_weights(path + 'vgg_mnist_3_sub02.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = image.ImageDataGenerator(shear_range=0.05, channel_shift_range=10)\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "model_01 = fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01.save_weights(path + 'vgg_shear0.05_dropout0.5_model_test01_subset02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(path + 'vgg_mnist_'  + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,m in enumerate(models):\n",
    "    m.save_weights(path + 'vgg_mnist_' + str(i) + '.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = model_01.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_preds = np.stack([m.predict_generator(test_batches, test_batches.nb_sample) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = preds.clip(min=0.05, max=0.95)\n",
    "print preds[:5]\n",
    "filenames = test_batches.filenames\n",
    "ids = np.array([(f[f.find('/')+1:]) for f in filenames])\n",
    "ids.resize((1000, 1))\n",
    "subm = np.hstack((ids,preds))\n",
    "print subm[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd $path\n",
    "submission_file_name = 'trainset_01shear0.05_02no_aug_dropout0.5_model_01_sub04.csv'\n",
    "print subm[:5]\n",
    "np.savetxt(submission_file_name, subm, fmt='%s,%s,%s,%s,%s,%s,%s,%s,%s', header='image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rotation_range=10, width_shift_range=0.1, \n",
    "       height_shift_range=0.1, width_zoom_range=0.2, shear_range=0.15, zoom_range=0.1, \n",
    "       channel_shift_range=10., horizontal_flip=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3777 images belonging to 8 classes.\n",
      "Found 722 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, \n",
    "                               height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "\n",
    "batch_size=64\n",
    "batches = get_batches(train_path, gen, batch_size=batch_size)\n",
    "# batches = get_batches(train_path, batch_size=batch_size)\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "val_batches = get_batches(valid_path, shuffle=False, batch_size=batch_size)\n",
    "test_batches = get_batches(test_path, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir\n",
    "print DATA_HOME_DIR\n",
    "gen = image.ImageDataGenerator(rotation_range=180, horizontal_flip=True, vertical_flip=True )\n",
    "# Create a 'batch' of a single image\n",
    "img = np.expand_dims(ndimage.imread('/home/ubuntu/nbs/fish/fish_classification/data/train/SHARK/img_00247.jpg'),0)\n",
    "# Request the generator to create batches from this image\n",
    "aug_iter = gen.flow(img)\n",
    "# Get eight examples of these augmented images\n",
    "aug_imgs = [next(aug_iter)[0].astype(np.uint8) for i in range(8)]\n",
    "# The original\n",
    "plt.imshow(img[0])\n",
    "# Augmented data\n",
    "plots(aug_imgs, (40,30), 8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from utils import get_batches, onehot\n",
    "\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??gen.get_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model=vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features_01 = conv_model.predict_generator(batches, batches.nb_sample*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??conv_model.predict_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trn_features.shape\n",
    "print val_features.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??get_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_labels = np.vstack((trn_labels,trn_labels, trn_labels, trn_labels, trn_labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from utils import get_batches, onehot\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes \n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'da_train_convlayer_features.bc', trn_features)\n",
    "save_array(model_path + 'valid_convlayer_features.bc', val_features)\n",
    "save_array(model_path + 'test_convlayer_features.bc', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'da_train_convlayer_features_01.bc', trn_features_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18885, 512, 14, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_features = load_array(model_path + 'da_train_convlayer_features_01.bc')\n",
    "val_features = load_array(model_path + 'valid_convlayer_features.bc')\n",
    "test_features = load_array(model_path + 'test_convlayer_features.bc')\n",
    "trn_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bn_model.predict(test_features, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(8, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print trn_features.shape, trn_labels.shape\n",
    "print val_features.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(trn_features, trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "bn_model.optimizer.lr=0.0001\n",
    "bn_model.fit(trn_features, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(val_features, val_labels))\n",
    "bn_model.optimizer.lr=0.00001\n",
    "bn_model.fit(trn_features, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(val_features, val_labels))\n",
    "bn_model.optimizer.lr=0.00001\n",
    "bn_model.fit(trn_features, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(model_path+'latest_weights_no_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(model_path+'latest_weights_aug01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(model_path+'latest_weights_aug01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copy the weights from the pre-trained model.\n",
    "# NB: Since we're removing dropout, we want to half the weights\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fc_model.fit(trn_features, trn_labels, nb_epoch=8, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.save_weights(model_path+'no_dropout01.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# dim_ordering='tf' uses tensorflow dimension ordering,\n",
    "#   which is the same order as matplotlib uses for display.\n",
    "# Therefore when just using for display purposes, this is more convenient\n",
    "gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "       height_shift_range=0.1, width_zoom_range=0.2, shear_range=0.15, zoom_range=0.1, \n",
    "       channel_shift_range=10., horizontal_flip=True, dim_ordering='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "no_of_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `ImageDataGenerator` not found.\n"
     ]
    }
   ],
   "source": [
    "??ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3404 images belonging to 8 classes.\n",
      "Found 373 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
    "batches = vgg.get_batches(train_path, gen, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "vgg.model.optimizer.lr = 0.01   # ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg.model\n",
    "layers = model.layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg.finetune"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "opt = RMSprop(lr=0.1)\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "for layer in layers[12:]: layer.trainable=True\n",
    "for epoch in range(12, 20):\n",
    "    K.set_value(opt.lr, 0.001)\n",
    "    vgg.model.load_weights('/home/ubuntu/nbs/fish/fish_classification/data/results/ft10.h5')\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft11.h5'\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "print test_path\n",
    "vgg.model.load_weights('/home/ubuntu/nbs/fish/fish_classification/data/results/ft10.h5')\n",
    "batches, preds = vgg.test('/home/ubuntu/nbs/fish/fish_classification/data/test/', batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "print test_path\n",
    "vgg.model.load_weights('/home/ubuntu/nbs/fish/fish_classification/data/models/no_dropout01.h5')\n",
    "batches, preds = vgg.test('/home/ubuntu/nbs/fish/fish_classification/data/test/', batch_size = batch_size*2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = preds.clip(min=0.05, max=0.95)\n",
    "print preds[:5]\n",
    "filenames = batches.filenames\n",
    "filenames = batches.filenames\n",
    "ids = np.array([(f[f.find('/')+1:]) for f in filenames])\n",
    "ids.resize((1000, 1))\n",
    "subm = np.hstack((ids,preds))\n",
    "print subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `vgg.model.save_array` not found.\n"
     ]
    }
   ],
   "source": [
    "?vgg.model.save_array"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_array(results_path + 'test_preds.dat', preds)\n",
    "save_array(results_path + 'ids.dat', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5 validate the preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_labels = val_batches.classes #0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = preds[:]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6 submit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'ids.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Raw Predictions: \" + str(preds[:5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission_aug01.csv'\n",
    "print subm[:5]\n",
    "np.savetxt(submission_file_name, subm, fmt='%s,%s,%s,%s,%s,%s,%s,%s,%s', header='image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT', comments='')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink('/home/ubuntu/nbs/fish/fish_classification/'+submission_file_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
